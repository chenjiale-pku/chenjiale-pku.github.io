[{"authors":null,"categories":null,"content":"I am a senior student at Turing Class, Peking University. My research interests mainly lie in the intersection of theoretical computer science and economics. I\u0026rsquo;m currently working with Asst. Prof. Yuqing Kong on crowdsourcing, and with Prof. Jason Hartline on online algorithms and exam-grading systems.\nDuring Spring 2021, I was working with Prof. Ariel Procaccia on Markov decision process and fair division.\nCurriculum Vitae. --","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"I am a senior student at Turing Class, Peking University. My research interests mainly lie in the intersection of theoretical computer science and economics. I\u0026rsquo;m currently working with Asst. Prof. Yuqing Kong on crowdsourcing, and with Prof.","tags":null,"title":"Jiale Chen","type":"authors"},{"authors":["Jiale Chen","Yuqing Kong","Yuxuan Lu"],"categories":[],"content":"","date":1625633496,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1625633496,"objectID":"e78a63c26d591a0a708cbda88f83cc51","permalink":"https://chenjiale-pku.github.io/publication/chen-2021-equal.html","publishdate":"2021-07-07T12:51:36+08:00","relpermalink":"/publication/chen-2021-equal.html","section":"publication","summary":"In the setting where a group of agents is asked a single subjective multi-choice question (e.g. which one do you prefer? cat or dog?), we are interested in evaluating the quality of the collected feedback. However, the collected statistics are not sufficient to reflect how informative the feedback is since fully informative feedback (equal affection of the choices) and fully uninformative feedback (random selection) have the same uniform statistics.\nHere we distinguish the above two scenarios by additionally asking for respondents' predictions about others' choices. We assume that informative respondents' predictions strongly depend on their own choices while uninformative respondents' do not. With this assumption, we propose a new definition for uninformative feedback and correspondingly design a family of evaluation metrics, called f-variety, for group-level feedback which can 1) distinguish informative feedback and uninformative feedback (separation) even if their statistics are both uniform and 2) decrease as the ratio of uninformative respondents increases (monotonicity). We validate our approach both theoretically and numerically. Moreover, we conduct two real-world case studies about 1) comparisons about athletes and 2) comparisons about stand-up comedians to show the superiority of our approach.","tags":[],"title":"Equal Affection or Random Selection: the Quality of Subjective Feedback from a Group Perspective","type":"publication"}]