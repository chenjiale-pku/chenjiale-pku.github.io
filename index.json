
    
    
    
    [{"authors":null,"categories":null,"content":"I am a first-year Ph.D. student in operations research at Stanford University, rotating with Prof. Amin Saberi and Prof. Aaron Sidford . Previously, I obtained my B.Sc., Summa Cum Laude in Computer Science and Technology from Turing Class, Peking University, advised by Prof. Yuqing Kong . During my undergraduate years, I am fortunate to have worked closely with Prof. Ariel Procaccia at Harvard University and Prof. Jason Hartline at Northwestern University.\nMy research interests lie in the intersection of theoretical computer science and economics, with a goal to provide elegant explanations and practical guidance for social phenomena. Recently I’ve been exploring topics in graph algorithms.\n","date":1683402141,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1683402141,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"I am a first-year Ph.D. student in operations research at Stanford University, rotating with Prof. Amin Saberi and Prof. Aaron Sidford . Previously, I obtained my B.Sc., Summa Cum Laude in Computer Science and Technology from Turing Class, Peking University, advised by Prof.","tags":null,"title":"Jiale Chen","type":"authors"},{"authors":["Jiale Chen","Jason Hartline and Onno Zoeter"],"categories":[],"content":"","date":1683402141,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1683402141,"objectID":"e9fd86b3c4e91aa772b888b7b1dfd587","permalink":"https://chenjiale-pku.github.io/publication/fairgrading/","publishdate":"2023-05-06T12:42:21-07:00","relpermalink":"/publication/fairgrading/","section":"publication","summary":"This paper studies grading algorithms for randomized exams. In a randomized exam, each student is asked a small number of random questions from a large question bank. The predominant grading rule is simple averaging, i.e., calculating grades by averaging scores on the questions each student is asked, which is fair ex-ante, over the randomized questions, but not fair ex-post, on the realized questions. The fair grading problem is to estimate the average grade of each student on the full question bank. The maximum-likelihood estimator for the Bradley-Terry-Luce model on the bipartite student-question graph is shown to be consistent with high probability when the number of questions asked to each student is at least the cubed-logarithm of the number of students. In an empirical study on exam data and in simulations, our algorithm based on the maximum-likelihood estimator significantly outperforms simple averaging in prediction accuracy and ex-post fairness even with a small class and exam size.","tags":[],"title":"Fair Grading Algorithms for Randomized Exams","type":"publication"},{"authors":["Jiale Chen"],"categories":[],"content":"","date":1657036800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1657036800,"objectID":"70377b70264ee41a31b8c974fed42697","permalink":"https://chenjiale-pku.github.io/publication/locallyfaircakecutting/","publishdate":"2022-07-06T00:00:00+08:00","relpermalink":"/publication/locallyfaircakecutting/","section":"publication","summary":"We studied the local fairness of the cake-cutting problem. We proposed an Ω(n2) lower bound for the local envy-freeness under star graphs with constraints and proposed a partial locally envyfree protocol for 4-Path which can be easily extended to 5-Path.","tags":[],"title":"A Note on Locally Fair Cake-Cutting","type":"publication"},{"authors":["Jiale Chen","Yuqing Kong","Yuxuan Lu"],"categories":[],"content":"","date":1625633496,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1625633496,"objectID":"e78a63c26d591a0a708cbda88f83cc51","permalink":"https://chenjiale-pku.github.io/publication/chen-2021-equal/","publishdate":"2021-07-07T12:51:36+08:00","relpermalink":"/publication/chen-2021-equal/","section":"publication","summary":"In the setting where a group of agents is asked a single subjective multi-choice question (e.g. which one do you prefer? cat or dog?), we are interested in evaluating the quality of the collected feedback. However, the collected statistics are not sufficient to reflect how informative the feedback is since fully informative feedback (equal affection of the choices) and fully uninformative feedback (random selection) have the same uniform statistics.\nHere we distinguish the above two scenarios by additionally asking for respondents' predictions about others' choices. We assume that informative respondents' predictions strongly depend on their own choices while uninformative respondents' do not. With this assumption, we propose a new definition for uninformative feedback and correspondingly design a family of evaluation metrics, called f-variety, for group-level feedback which can 1) distinguish informative feedback and uninformative feedback (separation) even if their statistics are both uniform and 2) decrease as the ratio of uninformative respondents increases (monotonicity). We validate our approach both theoretically and numerically. Moreover, we conduct two real-world case studies about 1) comparisons about athletes and 2) comparisons about stand-up comedians to show the superiority of our approach.","tags":[],"title":"Equal Affection or Random Selection: the Quality of Subjective Feedback from a Group Perspective","type":"publication"}]